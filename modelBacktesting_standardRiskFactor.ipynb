{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Financial Model Backtesting: Are historic stock returns compatible with a specified stochastic model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This document implements a simple backtesting methodology to assess, whether a given stock price process\n",
    "is compatible with a predefined stochastic model. Similar test are employed by numerous investment firms\n",
    "within regulatory model backtesting.\n",
    "\n",
    "This document serves as an illustration of techniques and limitations and is intended solely for educational and entertainment purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's load what we will need\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.sandbox.distributions.extras as extras\n",
    "import statsmodels.distributions.empirical_distribution as empirical_distribution\n",
    "import scipy.interpolate as interpolate\n",
    "import scipy.stats as ss\n",
    "import matplotlib.pyplot as plt  \n",
    "import matplotlib.patches as mpatches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warum Up: Check if a sample is likely to have been taken from a normal distribution with specified mean and variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main steps are:\n",
    " 1. Create a reference sample from the model.\n",
    " 2. Create a good and a bad sample that are respectively tested against the model sample. \n",
    "    1. The good sample is taken from the model.\n",
    "    2. The bad sample is taken from another distribution\n",
    " 3. Probability Integral Transform (PIT) is computed based on the model distribution and applied to the good and bad samples.\n",
    " 4. The obtained PIT values are tested against uniformity using standard tests and p-Values are computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorry PEP8 for camelCase throughout.\n",
    "\n",
    "# Let's take a sample from a specified normal distribution and test if it came from another normal distribution.\n",
    "modelSample = np.random.normal(2,1,10000) #this is sampled from our 'model'. Later this will be the model of stock prices\n",
    "testSample = np.random.normal(2,1,100) #A much smaller 'test sample'. This will be the 'realized returns'\n",
    "\n",
    "badTestSample = np.random.normal(1.5,1,100) #This is quite extreme, but it serves the illustration purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We compute the Probability Integral Transform (PIT) of our test sample: \n",
    "# https://en.wikipedia.org/wiki/Probability_integral_transform\n",
    "\n",
    "# The point is that if the test sample has been sampled from the distribution of the model, then we expect\n",
    "# that we obtain a uniform distribution\n",
    "\n",
    "# To compute the PIT we begin by setting up the empirical cumulative distribution function (ECDF) of our model:\n",
    "empiricalModelCDF = empirical_distribution.ECDF(modelSample)\n",
    "\n",
    "# We plug in the testSamples to compute the PITs\n",
    "pitValues = empiricalModelCDF(testSample)\n",
    "badPITValues = empiricalModelCDF(badTestSample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot p values and histograms to visually assess if they are uniform\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(20, 10))\n",
    "axs[0, 0].plot(pitValues, 'o')\n",
    "axs[0, 1].plot(badPITValues, 'o', c = 'red')\n",
    "axs[1, 0].hist(pitValues, bins =10)\n",
    "axs[1, 1].hist(badPITValues, bins =10, color = 'red')\n",
    "\n",
    "fig.legend(['Good Pits','Bad Pits'], loc='lower right', bbox_to_anchor=(1,0.0), ncol=2, bbox_transform=fig.transFigure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that the histogram on the left hand side much more resembles a uniform distribution than the one on the right hand side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We run classical statistical tests to check if the sample truely came from the model\n",
    "\n",
    "# Let's start with the good sample\n",
    "ksTest = ss.kstest(pitValues, 'uniform') #Kholmogorov Smirnoff Test\n",
    "cmTest = ss.cramervonmises(pitValues, 'uniform') #Cramer von Mises Test\n",
    "\n",
    "# What about the bad sample?\n",
    "badKSTest = ss.kstest(badPITValues, 'uniform') #Kholmogorov Smirnoff Test\n",
    "badCMTest = ss.cramervonmises(badPITValues, 'uniform') #Cramer von Mises Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the measured test statistics and pValues.\n",
    "\n",
    "print('Good sample: ' + str(ksTest))\n",
    "print('Good sample: ' + str(cmTest))\n",
    "\n",
    "print('Bad sample: ' + str(badKSTest))\n",
    "print('Bad sample: ' + str(badCMTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We conclude that the bad sample is quite extreme given the model, while the probability of obtaining a test outcome at least as extreme as the one measured is high for the true sample. For completeness one should also run some confidence interval test, but I'll skip this for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if a specific path is likely a realization of a Geometric Brownian Motion with specified mean and variance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We roughly follow the main steps of the preceding section: Creating a reference sample from a specified model and comparing a good and a bad path to the reference. \n",
    "The main differences with respect to above setting are:\n",
    " 1. Non-stationarity: The model depends on time. Every sample is taken from a new distribution.\n",
    " 2. One historic path: In reality only one historic realization of a stock price process is available.\n",
    "\n",
    "The model used here will be of Geometric Brownian Motion (GBM) type. Only one 'good' and one 'bad' path will be created for this example. In order to test the hypothesis that the 'good' or 'bad' path came from the specified model, we will follow a 'running window' approach: At each step in time we create a PIT by comparing the realized (historic stock value) versus the model. Remark that the GBM model specifies the distribution of the stock price observation is log-normal. For each step in time we will compute one PIT based on the model forecast at that point in time. We proceed by collecting all PITs from different times and testing them against uniformity. The main steps are:\n",
    "\n",
    "\n",
    " 1. Create a reference sample from a GBM model.\n",
    " 2. Create a good and a bad path that are respectively tested against the model. Those samples will be considered as the 'realized historic stock prices' in this example.\n",
    "    1. The good path is taken from the model.\n",
    "    2. The bad path is taken from a misspecified GBM.\n",
    " 3. A PIT is computed at each time step individually: At each time the model forecast is computed and the PIT transform is applied to the good and bad 'historic' realizations.\n",
    " 4. The obtained PIT values are tested as a bulk against uniformity using standard tests.\n",
    " \n",
    "To be specific: In this example the $0$-hypothesis is that the stock price at each time step is distributed \n",
    "according to a log-normal distribution, whose time-dependent parameters are so as given by the specified GBM process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method creates sample paths of Geometric Brownian Motion (GBM)\n",
    "\n",
    "def gbm(n_sim, n_samples, dt, mu, sigma, s0):\n",
    "    mean = (mu-0.5*sigma**2)*dt\n",
    "    s = s0*np.ones((n_sim, n_samples+1))\n",
    "    bm = sigma * np.sqrt(dt) * np.random.normal(0, 1, (n_sim, n_samples))\n",
    "    s[:, 1:s.shape[1]] = s0*np.exp(np.cumsum(mean + bm, 1))\n",
    "    return s\n",
    "\n",
    "# Parameters\n",
    "\n",
    "n_sim = 10000 # this is the number of paths\n",
    "n_samples = 100 # time disrectization: number of individual realizations per path\n",
    "s0=1 # initial value of the asset\n",
    "sigma=0.1 # volatility\n",
    "mu = 0.05 # drift\n",
    "dt = n_samples/200 #200 business days per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a sample from a specified GBM and good and bad historic paths.\n",
    "\n",
    "modelSamplePaths = gbm(n_sim, n_samples, dt, mu, sigma, s0)\n",
    "\n",
    "goodPath = gbm(1, n_samples, dt, mu, sigma, s0)\n",
    "badPath = gbm(1, n_samples, dt, mu, 0.3, s0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For illustration, here is a plot of some model paths, as well as, the good and the bad realized paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10),facecolor='yellow')\n",
    "plt.plot(modelSamplePaths[0:100,:].T, c = 'grey', alpha = 0.3)\n",
    "plt.plot(goodPath.T, c = 'green')\n",
    "plt.plot(badPath.T, c = 'red')\n",
    "\n",
    "red_patch = mpatches.Patch(color='red', label='Bad Path')\n",
    "green_patch = mpatches.Patch(color='green', label='Good Path')\n",
    "grey_patch = mpatches.Patch(color='grey', label='Model Paths')\n",
    "\n",
    "plt.legend(loc=\"upper left\",handles=[red_patch, green_patch, grey_patch])\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Price')\n",
    "plt.ylim([0,25])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's go and compute the PITs. Start by getting the ECDFs at different time steps\n",
    "\n",
    "ECDFs = []\n",
    "for i in range(n_samples):\n",
    "    ECDFs.append(empirical_distribution.ECDF(np.log(modelSamplePaths[:,i+1]) - np.log(modelSamplePaths[:,i])))\n",
    "#Notice the difference in above formula. It occurs because we are testing for a 0-hypothesis that involves the \n",
    "#increments of the stochastic process.\n",
    "\n",
    "goodPathPITValues = np.empty(n_samples)\n",
    "badPathPITValues = np.empty(n_samples)\n",
    "\n",
    "# Computing the respective PIT values\n",
    "for i, ECDF in enumerate(ECDFs):\n",
    "    goodPathPITValues[i] = ECDF(np.log(goodPath[:,i+1])-np.log(goodPath[:,i]))\n",
    "    badPathPITValues[i] = ECDF(np.log(badPath[:,i+1])-np.log(badPath[:,i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot p values and histograms to visually assess if they are uniform\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(20, 10))\n",
    "axs[0, 0].plot(goodPathPITValues, 'o')\n",
    "axs[0, 1].plot(badPathPITValues, 'o', c = 'red')\n",
    "axs[1, 0].hist(goodPathPITValues, bins =10)\n",
    "axs[1, 1].hist(badPathPITValues, bins =10, color = 'red')\n",
    "\n",
    "fig.legend(['Good Pits','Bad Pits'], loc='lower right', bbox_to_anchor=(1,0.0), ncol=2, bbox_transform=fig.transFigure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We run classical statistical tests to check if the sample truely came from the model\n",
    "\n",
    "# Let's start with the good sample\n",
    "ksGoodPathTest = ss.kstest(goodPathPITValues, 'uniform') #Kholmogorov Smirnoff Test\n",
    "cmGoodPathTest = ss.cramervonmises(goodPathPITValues, 'uniform') #Cramer von Mises Test\n",
    "\n",
    "# What about the bad sample?\n",
    "ksBadPathTest = ss.kstest(badPathPITValues, 'uniform') #Kholmogorov Smirnoff Test\n",
    "cmBadPathCMTest = ss.cramervonmises(badPathPITValues, 'uniform') #Cramer von Mises Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the measured test statistics and pValues.\n",
    "\n",
    "print('Good path sample: ' + str(ksGoodPathTest))\n",
    "print('Good path sample: ' + str(cmGoodPathTest))\n",
    "\n",
    "print('Bad path sample: ' + str(ksBadPathTest))\n",
    "print('Bad path sample: ' + str(cmBadPathCMTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a real-world setting a stochastic process will be callibrated to the market and the\n",
    "realized path will be a sequence of historic market realizations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The non-stationarity of the stochastic model and the reliance on a single realized path for testing entail important limitations. We illustrate some points by examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The presence of drifts can be misleading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We construct an example, which is characterized by \n",
    " 1. No apparent relation between the stochastic model and the realized path;\n",
    " 2. High p-Values in statistical tests.\n",
    " \n",
    "For illustration we consider a simple model with a deterministic path, but the involved phenomenon is more general.\n",
    "Its occurrence is related to the presence of drift. The $0$-hypothesis to be tested is whether a deterministic path is compatible with stochastic process with uniform increments. Though this hypothesis is clearly wrong, statistical tests have high p-Values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We assume a deterministic path and a uniform model\n",
    "modelSamplePathsUni = np.cumsum(np.concatenate([np.ones((10000,1)), np.random.uniform(0, 1, size=(10000,100))], axis = 1),1)\n",
    "\n",
    "#A bad path for illustration\n",
    "badPath = 1 + np.cumsum(np.linspace(0,1,101))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10),facecolor='yellow')\n",
    "plt.plot(modelSamplePathsUni[0:30,:].T, c = 'grey', alpha = 0.3)\n",
    "plt.plot(badPath, c = 'red')\n",
    "\n",
    "red_patch = mpatches.Patch(color='red', label='Bad Path')\n",
    "grey_patch = mpatches.Patch(color='grey', label='Model Paths')\n",
    "\n",
    "plt.legend(loc=\"upper left\",handles=[red_patch, green_patch, grey_patch])\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Price')\n",
    "plt.ylim([0,50])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's compute the PITs. Start by getting the ECDFs at different time steps\n",
    "\n",
    "ECDFs = []\n",
    "for i in range(n_samples):\n",
    "    ECDFs.append(empirical_distribution.ECDF(modelSamplePathsUni[:,i+1]-modelSamplePathsUni[:,i]))\n",
    "\n",
    "badPathPITValues = np.empty(n_samples)\n",
    "\n",
    "# Computing the respective PIT values\n",
    "for i, ECDF in enumerate(ECDFs):\n",
    "    badPathPITValues[i] = ECDF(badPath[i+1]-badPath[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot p values and histograms to visually assess if they are uniform\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(20, 10))\n",
    "axs[0].plot(badPathPITValues, 'o', c = 'red')\n",
    "axs[1].hist(badPathPITValues, bins =10, color = 'red')\n",
    "\n",
    "fig.legend(['Bad Pits'], loc='lower right', bbox_to_anchor=(1,0.0), ncol=2, bbox_transform=fig.transFigure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We run classical statistical tests to check if the sample truely came from the model\n",
    "\n",
    "ksBadPathTest = ss.kstest(badPathPITValues, 'uniform') #Kholmogorov Smirnoff Test\n",
    "cmBadPathCMTest = ss.cramervonmises(badPathPITValues, 'uniform') #Cramer von Mises Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the measured test statistics and pValues.\n",
    "\n",
    "print('Bad path sample: ' + str(ksBadPathTest))\n",
    "print('Bad path sample: ' + str(cmBadPathCMTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The stochastic model has uniform increments and the realized path has drift that is characterized by increasing increments. The drift is chosen such as to ensure a small PIT in the beginning of the the testing episode, and a large PIT at the the end. The increase in PITs is essentially linear. The collection of PITs over all involved time steps presents itself as a uniform distribution. Being clearly wrong the $0$-hypothesis has high p-Values. The point is that if multiple realized paths could be compared at each time step statistical tests would be able to reject the hypothesis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Stats",
   "language": "python",
   "name": "stats"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
