{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Financial Model Backtesting: Are historic stock returns compatible with a  stochastic model specified by the first four moments?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This documents builds on the know-how and methodology of modelBacktesting_standardRiskFactor.ipynb in the same repo. This document implements a backtesting methodology to assess if a given stock price process\n",
    "is compatible with a predefined stochastic model. The predefined stochastic model is characterized by prescribing the first four moments of each increments distribution.\n",
    "\n",
    "The document is a beta version, currently under construction...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's load what we will need\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.sandbox.distributions.extras as extras\n",
    "import statsmodels.distributions.empirical_distribution as empirical_distribution\n",
    "import scipy.interpolate as interpolate\n",
    "import scipy.stats as ss\n",
    "import matplotlib.pyplot as plt  \n",
    "import matplotlib.patches as mpatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load historic returns data\n",
    "\n",
    "historicReturns = pd.read_csv('monthly_returns_forward.txt')\n",
    "\n",
    "historicReturns['lead_ret'] = pd.to_numeric(historicReturns['lead_ret'], errors='coerce')\n",
    "historicReturns['lead_retx'] = pd.to_numeric(historicReturns['lead_retx'], errors='coerce')\n",
    "historicReturns=historicReturns.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the moments data. All moments are interpreted as desribing a distribution of returns one month into the future.\n",
    "\n",
    "datesDf = pd.read_csv('all_dates.txt', header=None)\n",
    "permnoDf = pd.read_csv('permno.txt', header=None)\n",
    "\n",
    "expectedReturnsDf = pd.read_csv('P_ER.txt', header=None)\n",
    "varianceDf = pd.read_csv('P_variance.txt', header=None)\n",
    "skewnessDf = pd.read_csv('P_skewness.txt', header=None)\n",
    "kurtosisDf = pd.read_csv('P_kurtosis.txt', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is running a PIT based test for a certain PERMNO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permnoId = 0\n",
    "\n",
    "referenceSampleSize = 10000\n",
    "\n",
    "permno = permnoDf.values[permnoId,0]\n",
    "\n",
    "print(permno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice historic returns appropriately and format time data\n",
    "\n",
    "historicReturnsPermno = historicReturns[historicReturns['PERMNO']==permno][['DATE','lead_ret']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful dates\n",
    "\n",
    "historicReturnsPermnoUsefulDates = []\n",
    "for i in range(historicReturnsPermno['DATE'].shape[0]):\n",
    "    historicReturnsPermnoUsefulDates.append( historicReturnsPermno['DATE'].values.astype('str')[i][4:6] + '/' + historicReturnsPermno['DATE'].values.astype('str')[i][6:] + '/' + historicReturnsPermno['DATE'].values.astype('str')[i][:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a reference sample from the model. This is interpreted as a sample of distribution outcomes.\n",
    "\n",
    "def sampleFromDistributionWithSpecifiedMoments(mu, sigma, skew, kurt, size, sd_wide=10):\n",
    "   f = extras.pdf_mvsk([mu, sigma, skew, kurt])\n",
    "   x = np.linspace(mu - sd_wide * sigma, mu + sd_wide * sigma, num=500)\n",
    "   y = [f(i) for i in x]\n",
    "   yy = np.cumsum(y) / np.sum(y)\n",
    "   inv_cdf = interpolate.interp1d(yy, x, fill_value=\"extrapolate\")\n",
    "   rr = np.random.rand(size)\n",
    "\n",
    "   return inv_cdf(rr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampledModelIncrements = np.empty((datesDf.shape[0], referenceSampleSize))\n",
    "\n",
    "\n",
    "# loop over all dates and get the reference samples:\n",
    "for dateId in range(datesDf.shape[0]):\n",
    "    sampledModelIncrements[dateId,:] = sampleFromDistributionWithSpecifiedMoments(\n",
    "        expectedReturnsDf.values[permnoId, dateId],\n",
    "        varianceDf.values[permnoId, dateId],\n",
    "        skewnessDf.values[permnoId, dateId],\n",
    "        kurtosisDf.values[permnoId, dateId],\n",
    "        referenceSampleSize)\n",
    "    \n",
    "# from all sampled model increments we subtract 1 as this is their current gauging (gross returns +1)\n",
    "sampledModelIncrements -=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here are 20 typical paths of your model. Where NAN are given we extrapolate flat.\n",
    "\n",
    "modelSamplePaths = np.concatenate([np.zeros((1,sampledModelIncrements.shape[1])),np.nancumsum(sampledModelIncrements,0)],0)\n",
    "\n",
    "plt.figure(figsize=(20, 10),facecolor='yellow')\n",
    "plt.plot(modelSamplePaths[:,0:20], c = 'grey', alpha = 0.3)\n",
    "#plt.plot(goodPath.T, c = 'green')\n",
    "\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Price')\n",
    "plt.ylim([-0.5,4])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by getting the ECDFs at different time steps\n",
    "\n",
    "ECDFs = {}\n",
    "for dateId in range(datesDf.shape[0]):\n",
    "    if np.isnan(sampledModelIncrements[dateId,:]).any():\n",
    "        continue\n",
    "    ECDFs[dateId] = empirical_distribution.ECDF(sampledModelIncrements[dateId,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the PIT values of the permno under consideration\n",
    "\n",
    "PITs = np.empty(max(ECDFs))\n",
    "PITs[:] = np.nan\n",
    "historicPath  = {}\n",
    "historicPath[0] = 0.0\n",
    "for key, ECDF in ECDFs.items():\n",
    "    backtestingDate = datesDf[1][key]\n",
    "    \n",
    "    if not backtestingDate in historicReturnsPermnoUsefulDates:\n",
    "        continue\n",
    "    historicPath[key + 1] = historicReturnsPermno['lead_ret'].values[historicReturnsPermnoUsefulDates.index(backtestingDate)]\n",
    "    if historicReturnsPermnoUsefulDates.index(backtestingDate) + 1 == historicReturnsPermno.shape[0]:\n",
    "        continue\n",
    "              \n",
    "    realizedReturn = historicReturnsPermno['lead_ret'].values[historicReturnsPermnoUsefulDates.index(backtestingDate) + 1] - historicReturnsPermno['lead_ret'].values[historicReturnsPermnoUsefulDates.index(backtestingDate)]\n",
    "\n",
    "        \n",
    "    PITs[key] = ECDF(realizedReturn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's compare 20 model paths versus the realized path of the model over the horizon\n",
    "#Here are 20 typical paths of your model. Where NAN are given we extrapolate flat.\n",
    "\n",
    "modelSamplePaths = np.concatenate([np.zeros((1,sampledModelIncrements.shape[1])),np.nancumsum(sampledModelIncrements,0)],0)\n",
    "\n",
    "historicPathNP = np.empty(modelSamplePaths.shape[0])\n",
    "historicPathNP[:] = np.nan\n",
    "for key, entry in historicPath.items():\n",
    "    historicPathNP[key] = entry\n",
    "\n",
    "plt.figure(figsize=(20, 10),facecolor='yellow')\n",
    "plt.plot(modelSamplePaths[:,0:20], c = 'grey', alpha = 0.3)\n",
    "plt.plot(historicPathNP, '-*', c = 'green')\n",
    "\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Price')\n",
    "plt.ylim([-0.5,4])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot PIT values and histograms to visually assess if they are uniform\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, figsize=(20, 10))\n",
    "axs[0].plot(PITs, 'o')\n",
    "axs[1].hist(PITs, bins = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We run classical statistical tests to check if the sample truely came from the model\n",
    "validPITs = PITs[ np.logical_not(np.isnan(PITs))]\n",
    "\n",
    "ksTest = ss.kstest(validPITs, 'uniform') #Kholmogorov Smirnoff Test\n",
    "cmTest = ss.cramervonmises(validPITs, 'uniform') #Cramer von Mises Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the measured test statistics and pValues.\n",
    "print('Number of valid PITs ' + str(validPITs.shape[0]))\n",
    "print('KS test: ' + str(ksTest))\n",
    "print('CM test: ' + str(cmTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapped loop over multiple PERMNOs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap data cleaning and computation of PITS into a minimal function\n",
    "\n",
    "def minimalBacktest(permnoId, historicReturnsPermnoUsefulDates):\n",
    "    \n",
    "    sampledModelIncrements = np.empty((datesDf.shape[0], referenceSampleSize))\n",
    "\n",
    "    for dateId in range(datesDf.shape[0]):\n",
    "        sampledModelIncrements[dateId,:] = sampleFromDistributionWithSpecifiedMoments(\n",
    "            expectedReturnsDf.values[permnoId, dateId],\n",
    "            varianceDf.values[permnoId, dateId],\n",
    "            skewnessDf.values[permnoId, dateId],\n",
    "            kurtosisDf.values[permnoId, dateId],\n",
    "            referenceSampleSize)\n",
    "\n",
    "    sampledModelIncrements -=1\n",
    "    \n",
    "    ECDFs = {}\n",
    "    for dateId in range(datesDf.shape[0]):\n",
    "        if np.isnan(sampledModelIncrements[dateId,:]).any():\n",
    "            continue\n",
    "        ECDFs[dateId] = empirical_distribution.ECDF(sampledModelIncrements[dateId,:])\n",
    "\n",
    "    PITs = np.empty(max(ECDFs))\n",
    "    PITs[:] = np.nan\n",
    "\n",
    "    for key, ECDF in ECDFs.items():\n",
    "        backtestingDate = datesDf[1][key]\n",
    "        if not backtestingDate in historicReturnsPermnoUsefulDates:\n",
    "            continue\n",
    "        if historicReturnsPermnoUsefulDates.index(backtestingDate) + 1 == historicReturnsPermno.shape[0]:\n",
    "            continue\n",
    "\n",
    "        realizedReturn = historicReturnsPermno['lead_ret'].values[historicReturnsPermnoUsefulDates.index(backtestingDate) + 1] - historicReturnsPermno['lead_ret'].values[historicReturnsPermnoUsefulDates.index(backtestingDate)]\n",
    "        PITs[key] = ECDF(realizedReturn)\n",
    "        \n",
    "    validPITs = PITs[np.logical_not(np.isnan(PITs))]\n",
    "\n",
    "    ksTest = ss.kstest(validPITs, 'uniform')\n",
    "    cmTest = ss.cramervonmises(validPITs, 'uniform')\n",
    "\n",
    "    return (validPITs.shape[0], ksTest, cmTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testResults = {}\n",
    "\n",
    "for permnoId in range(permnoDf.values.shape[0]):\n",
    "    permno = permnoDf.values[permnoId,0]\n",
    "    print('Running for PERMNO ' + str(permno))\n",
    "    historicReturnsPermno = historicReturns[historicReturns['PERMNO']==permno][['DATE','lead_ret']]\n",
    "    if not historicReturnsPermno.values.size:\n",
    "        testResults[permno] = 'NoReturnsData'\n",
    "        continue\n",
    "        \n",
    "    historicReturnsPermnoUsefulDates = []\n",
    "    for i in range(historicReturnsPermno['DATE'].shape[0]):\n",
    "        historicReturnsPermnoUsefulDates.append( historicReturnsPermno['DATE'].values.astype('str')[i][4:6] + '/' + historicReturnsPermno['DATE'].values.astype('str')[i][6:] + '/' + historicReturnsPermno['DATE'].values.astype('str')[i][:4])\n",
    "    \n",
    "    try:\n",
    "        testResults[permno] = minimalBacktest(permnoId, historicReturnsPermnoUsefulDates)\n",
    "    except:\n",
    "        testResults[permno] = 'TestsFailed'\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(testResults)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Stats",
   "language": "python",
   "name": "stats"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
